{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snatched11/100-Days-Of-PyTorch/blob/main/Day%201-%20Tensors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a Tensor?**\n",
        "* A tensor is a multidimensional array, like NumPy arrays but optimized for GPU acceleration.\n",
        "\n",
        "* Everything in PyTorch ‚Äî embeddings, model weights, attention matrices ‚Äî is a tensor.\n",
        "\n",
        "* Tensors can track gradients for backprop using requires_grad=True."
      ],
      "metadata": {
        "id": "9JzmnoHV4P4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Property        | Description                                |\n",
        "| --------------- | ------------------------------------------ |\n",
        "| `shape`         | Dimensions of the tensor, e.g., `(3,4)`    |\n",
        "| `dtype`         | Data type (`float32`, `int64`)             |\n",
        "| `device`        | Location of the tensor (`cpu` or `cuda:0`) |\n",
        "| `requires_grad` | Tracks operations for autograd             |\n"
      ],
      "metadata": {
        "id": "4JAVfn3o5oEP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor creation**"
      ],
      "metadata": {
        "id": "8hC_5sz86LYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = torch.tensor ([1,2,3], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "qplLGHyP6fjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = torch.zeros(2, 3)\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jAeTw0R6v6g",
        "outputId": "b685bb33-3cd3-4aaf-be9f-8534ec13836d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(2, 3)\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "li2wYecR67xs",
        "outputId": "90cb5e94-1198-40b5-c67c-5745acfebbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2TbTOK57B5Y",
        "outputId": "fdd2134b-9a4c-43d7-aca3-515c7862dc05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_device = torch.zeros(3,3).to(device)\n",
        "print(\"Tensor device:\", tensor_on_device.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tC36B9z7bl_",
        "outputId": "3d7a3221-9a7a-416c-a9ab-191f927f1505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rWEnMDBL7g5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Challenge**"
      ],
      "metadata": {
        "id": "1wYRNvbU75jE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a 3D tensor of shape (2,3,4) with random numbers\n",
        "tensor3d = torch.randn(2,3,4)\n",
        "\n",
        "# Step 2: Move it to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "tensor3d = tensor3d.to(device)\n",
        "\n",
        "# Step 3: Multiply by 2\n",
        "tensor3d = tensor3d * 2\n",
        "\n",
        "# Step 4: Slice the first 2 \"matrices\" along the first axis\n",
        "sliced = tensor3d[:2,:,:]\n",
        "\n",
        "# Step 5: Print shape, dtype, device, and the resulting tensor\n",
        "print (\"Tensor 3d \", tensor3d)\n",
        "print(\"Sliced tensor shape:\", sliced.shape)\n",
        "print(\"Dtype:\", sliced.dtype)\n",
        "print(\"Device:\", sliced.device)\n",
        "print(\"Tensor:\", sliced)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsm1EXJP770s",
        "outputId": "826c01d0-81c2-4d7b-d96a-e2a004e0bd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor 3d  tensor([[[ 1.7096, -1.1733,  0.5819,  2.1277],\n",
            "         [-1.6149, -0.9564, -2.2833, -2.0570],\n",
            "         [-1.1769, -0.7180, -1.0052, -0.4275]],\n",
            "\n",
            "        [[-4.1561,  1.9215,  4.1073,  1.0599],\n",
            "         [ 2.8609, -0.9351,  2.5445, -2.6114],\n",
            "         [-1.4519,  1.9645,  2.4712,  0.0575]]])\n",
            "Sliced tensor shape: torch.Size([2, 3, 4])\n",
            "Dtype: torch.float32\n",
            "Device: cpu\n",
            "Tensor: tensor([[[ 1.7096, -1.1733,  0.5819,  2.1277],\n",
            "         [-1.6149, -0.9564, -2.2833, -2.0570],\n",
            "         [-1.1769, -0.7180, -1.0052, -0.4275]],\n",
            "\n",
            "        [[-4.1561,  1.9215,  4.1073,  1.0599],\n",
            "         [ 2.8609, -0.9351,  2.5445, -2.6114],\n",
            "         [-1.4519,  1.9645,  2.4712,  0.0575]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tensor3d**\n",
        "\n",
        "matrix 0  ‚Üí tensor3d[0]\n",
        "\n",
        "matrix 1  ‚Üí tensor3d[1]   ‚Üê this is the 2nd matrix\n"
      ],
      "metadata": {
        "id": "y_CzaMJx-NEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dropped = tensor3d[[0]]\n",
        "print(dropped.shape)\n",
        "print(dropped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-gVS2_n9zV4",
        "outputId": "2424f01b-dffd-481b-8e8e-3689bd35d6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 4])\n",
            "tensor([[[ 1.7096, -1.1733,  0.5819,  2.1277],\n",
            "         [-1.6149, -0.9564, -2.2833, -2.0570],\n",
            "         [-1.1769, -0.7180, -1.0052, -0.4275]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dropped = tensor3d[:1]\n",
        "print(dropped.shape)\n",
        "print(dropped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjXHdwkr98cM",
        "outputId": "eb3d4507-be7d-4245-a829-345573c7209f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 4])\n",
            "tensor([[[ 1.7096, -1.1733,  0.5819,  2.1277],\n",
            "         [-1.6149, -0.9564, -2.2833, -2.0570],\n",
            "         [-1.1769, -0.7180, -1.0052, -0.4275]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = tensor3d[1:]\n",
        "print(result)\n",
        "print(result.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLpDiZd-_bhJ",
        "outputId": "ee9134de-e6ef-4387-c266-e0d8b57679f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-4.1561,  1.9215,  4.1073,  1.0599],\n",
            "         [ 2.8609, -0.9351,  2.5445, -2.6114],\n",
            "         [-1.4519,  1.9645,  2.4712,  0.0575]]])\n",
            "torch.Size([1, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformer and tensor connection**"
      ],
      "metadata": {
        "id": "f-CeuH1tC9dM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "S1: \"I like AI\"\n",
        "\n",
        "S2: \"AI likes math\"\n",
        "\n",
        "S3: \"Math is fun\"\n",
        "\n",
        "S4: \"I like math\"\n",
        "\n",
        "**Batch size = 4**\n"
      ],
      "metadata": {
        "id": "eSZUMIWnDPfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2Ô∏è‚É£ Tokenization (numbers only)**\n",
        "\n",
        "I ‚Üí 1\n",
        "\n",
        "like ‚Üí 2\n",
        "\n",
        "AI ‚Üí 3\n",
        "\n",
        "likes ‚Üí 4\n",
        "\n",
        "math ‚Üí 5\n",
        "\n",
        "is ‚Üí 6\n",
        "\n",
        "fun ‚Üí 7"
      ],
      "metadata": {
        "id": "4EViB8yNDYRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenized + padded to same length (seq_len = 3):**\n",
        "\n",
        "[\n",
        "\n",
        " [1, 2, 3],   # I like AI\n",
        "\n",
        " [3, 4, 5],   # AI likes math\n",
        "\n",
        " [5, 6, 7],   # Math is fun\n",
        "\n",
        " [1, 2, 5]    # I like math\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "ONR3b4uaDpNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = torch.tensor([\n",
        "    [1,2,3],\n",
        "    [3,4,5],\n",
        "    [5,6,7],\n",
        "    [1,2,5]\n",
        "])\n",
        "\n",
        "#(batch=4, seq_len=3)"
      ],
      "metadata": {
        "id": "NcWJMLyYEMxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3Ô∏è‚É£ Embedding**\n",
        "\n",
        "vocab_size x hidden_dim\n",
        "\n",
        "Assume, hidden_dim = 6"
      ],
      "metadata": {
        "id": "mzCSIVbSEzik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_table = torch.randn(8, 6)  # vocab_size=8\n",
        "X = embedding_table[tokens]\n",
        "print(X.shape)\n",
        "X\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYSxw9W_FCWg",
        "outputId": "12b232b4-ec08-4061-b0e3-fdde85bd60e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 3, 6])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1929,  0.3516,  0.3627,  0.4145, -0.6670, -1.1954],\n",
              "         [-0.8289, -0.9557,  0.4611,  0.0383, -1.2085, -1.7519],\n",
              "         [-0.6806, -0.0751, -1.3931,  0.9885, -0.4611, -0.2347]],\n",
              "\n",
              "        [[-0.6806, -0.0751, -1.3931,  0.9885, -0.4611, -0.2347],\n",
              "         [ 0.2808, -0.7160,  1.3994, -0.4271, -0.0214,  1.0952],\n",
              "         [ 0.2251, -1.8447,  0.8342,  0.2588, -0.0382,  0.5012]],\n",
              "\n",
              "        [[ 0.2251, -1.8447,  0.8342,  0.2588, -0.0382,  0.5012],\n",
              "         [-1.6523,  0.6432, -0.0726,  0.0510, -0.5297, -1.1286],\n",
              "         [-1.6155,  0.3753, -1.5254, -0.6479,  1.3709,  0.2496]],\n",
              "\n",
              "        [[-0.1929,  0.3516,  0.3627,  0.4145, -0.6670, -1.1954],\n",
              "         [-0.8289, -0.9557,  0.4611,  0.0383, -1.2085, -1.7519],\n",
              "         [ 0.2251, -1.8447,  0.8342,  0.2588, -0.0382,  0.5012]]])"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Meaning:\n",
        "\n",
        "4 sentences\n",
        "\n",
        "each has 3 tokens\n",
        "\n",
        "each token is a 6-dim vector\n",
        "\n",
        "üìå This tensor is the input to the transformer\n",
        "\n",
        "4 sentences ‚Üí batch dimension = 4\n",
        "\n",
        "3 words per sentence ‚Üí seq_len = 3\n",
        "\n",
        "Each word becomes a vector ‚Üí hidden_dim = 6"
      ],
      "metadata": {
        "id": "Fgj3oAWpECq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SuWkwMRzFrwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some interview questions**"
      ],
      "metadata": {
        "id": "0x6n6TJBGVqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is a tensor in PyTorch, and how is it different from a NumPy array?**\n",
        "\n",
        "Answer:\n",
        "\n",
        "A tensor is a multidimensional array that can:\n",
        "\n",
        "* Run on CPU or GPU\n",
        "\n",
        "* Track gradients for automatic differentiation\n",
        "\n",
        "* Integrate directly with deep learning models\n",
        "\n",
        "NumPy arrays:\n",
        "\n",
        "* Are CPU-only\n",
        "\n",
        "* Do not support autograd\n",
        "\n",
        "* Are not designed for large-scale neural networks\n",
        "\n",
        "üëâ In LLMs, every input, weight, and output is a tensor ‚Äî not a NumPy array."
      ],
      "metadata": {
        "id": "vsqw-nwiGaoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What does the shape (batch_size, seq_len, hidden_dim) represent?**\n",
        "\n",
        "Answer:\n",
        "\n",
        "* batch_size: number of sequences processed in parallel\n",
        "\n",
        "* seq_len: number of tokens per sequence\n",
        "\n",
        "* hidden_dim: size of vector representing each token\n",
        "\n",
        "Example:\n",
        "\n",
        "(4, 10, 768)\n",
        "\n",
        "\n",
        "Means:\n",
        "\n",
        "* 4 sentences\n",
        "\n",
        "* each with 10 tokens\n",
        "\n",
        "* each token represented as a 768-dim vector\n",
        "\n",
        "üëâ This is the standard input shape for transformers."
      ],
      "metadata": {
        "id": "ebyYumMmGqP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is dtype and why does it matter?**\n",
        "\n",
        "Answer:\n",
        "\n",
        "dtype defines the data type of a tensor (e.g. float32, float16, int64).\n",
        "\n",
        "It matters because:\n",
        "\n",
        "* It affects memory usage\n",
        "\n",
        "* It affects speed\n",
        "\n",
        "* It affects numerical stability\n",
        "\n",
        "Example:\n",
        "\n",
        "float32 ‚Üí standard training\n",
        "\n",
        "float16 / bfloat16 ‚Üí faster, less memory (used in LLMs)\n",
        "\n",
        "int64 ‚Üí token IDs\n",
        "\n",
        "üëâ Wrong dtype = slower models or runtime errors."
      ],
      "metadata": {
        "id": "qPvEocmQH0-k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why embeddings are 3D tensors ?**\n",
        "\n",
        "How the Tensor is Built\n",
        "You can think of the transition from a single word to a 3D tensor like this:\n",
        "\n",
        "* 1D (Vector): You have one word, like \"Apple.\" It is represented by a list of 512 numbers.\n",
        "\n",
        "* 2D (Matrix): You have a full sentence, like \"Apple is a fruit.\" Now you have a grid (a matrix) where each row is the vector for one of those words.\n",
        "\n",
        "* 3D (Tensor): You want to train the model on 100 sentences at once to make it faster. You stack 100 of those \"sentence matrices\" on top of each other. This \"stack\" is your 3D tensor.\n",
        "\n",
        "Why do we use 3D ?\n",
        "\n",
        "* Parallel Processing: Graphics cards (GPUs) are designed to do math on entire blocks of data simultaneously. Storing embeddings in a 3D tensor allows the GPU to calculate the relationships between all words in all sentences at the same time.\n",
        "\n",
        "* Contextual Awareness: In models like BERT or GPT, the model needs to see the entire sequence (Dimension 2) to understand that \"bank\" in a river context is different from \"bank\" in a money context"
      ],
      "metadata": {
        "id": "2thB9SFUH8eC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}